\section{XSS (Cross-Site Scripting)}
\textit{Cross-Site Scripting} (XSS) attacks are a type of injection in which malicious scripts are injected into trusted websites.
An attacker uses a web application to send malicious code, generally in the form of a browser-side script, to a different end user.
 The end user's browser has no way to know that the script should not be trusted and will execute the script. 
 It can access any cookies, session tokens or other sensitive information retained by the browser.
\subsection{Underlying idea}
The problem originates when user input is directly included in a web page output without proper validation or sanitization. In such cases, an attacker can inject malicious code that is executed by the victim’s browser. A typical reflected XSS attack follows this flow:
\begin{enumerate}
    \item The attacker identifies a website that reflects user-controlled input in its responses;
    \item The attacker crafts a malicious URL containing injected client-side code;
    \item The attacker uses social engineering techniques (e.g., email or messaging) to induce a victim to visit the malicious URL;
    \item The victim clicks the URL, and the injected code is executed in the context of the vulnerable website.
\end{enumerate}

\subsection{Example}
Consider a web application that allows users to search for content and displays the searched term on the results page.
Suppose the request is sent via the URL:
\begin{verbatim}
http://search.com/?query=<UserInput>
\end{verbatim}
The server dynamically generates the following response:
\begin{figure}[H]
  \begin{lstlisting}[language=HTML]
  <html>
    <body>
      Search results for: <UserInput>
      <ol>
        <li>http://example.com/result1</li>
        <li>http://example.com/result2</li>
      </ol>
    </body>
  </html>
  \end{lstlisting}
\end{figure}
If the attacker provides a malicious input such as:
\begin{verbatim}
  <script>alert('XSS')</script>
\end{verbatim}
the resulting URL becomes 
\begin{verbatim}
http://search.com/?query=<script>alert('XSS')</script>.
\end{verbatim}
When the victim visits this URL, the server reflects the input without sanitization, producing the following response:
\begin{figure}[H]
  \begin{lstlisting}[language=HTML]
  <html>
    <body>
      Search results for: <script>alert('XSS')</script>
      <ol>
        <li>http://example.com/result1</li>
        <li>http://example.com/result2</li>
      </ol>
    </body>
  </html>
  \end{lstlisting}
\end{figure}
As a consequence, the browser interprets the injected code as legitimate JavaScript and executes it in the security context of \texttt{search.com}. 
This allows the attacker to run arbitrary client-side code, potentially enabling actions such as session hijacking, credential theft, or manipulation of page content.

\subsection{XSS Types}
There are three main types of XSS attacks, based on how the malicious script is delivered and executed.
\subsubsection[short]{Reflected (non-persistent)}
  User-supplied input is immediately returned by the web application
  — for example, in search results, error messages, or redirects — without being properly encoded or escaped for safe rendering 
  in the browser. The payload is not stored on the server; instead, an attacker crafts a URL (or form) containing the payload 
  and convinces a victim (for example, via social engineering) to visit it. When the victim follows the link, the server responds 
  with a page that includes the malicious code, which then executes in the victim's browser.
  This is the most common type of XSS, and an example was already shown in the previous section.
  \subsubsection[short]{Stored (persistent)}
  User-supplied input is stored on the target server (for example, in a database, 
  profile field, comment, or message) and later served to other users without proper encoding or sanitization. 
  Because the malicious payload is persisted, any user who views the affected page may receive content that contains 
  executable script, which will run in that user's browser. 
  \paragraph{Example:}
  \begin{figure}[H]   
  \begin{lstlisting}[language=HTML]
  <!-- User submits comment containing: -->
  <div>Nice post!</div><script>alert('xss')</script>

  <!-- Application stores the comment and renders it-->
  <div class="comment">
    <div>Nice post!</div><script>alert('xss')</script>
  </div>
  \end{lstlisting}
  \end{figure}
  When other users load the page that lists comments, the server includes the stored comment directly in the HTML, and the script executes in each viewer's browser.
  \subsubsection[short]{DOM-Based}
  A form of XSS in which the entire unsafe data flow occurs in the browser. For example, the malicious payload could be included in the URL of the page, and a sensitive JavaScript operation (e.g., document.write, innerHTML, \dots) uses the data to modify the DOM in an unsafe way. 
  In this case, the server does not reflect or store the malicious input; instead, the vulnerability arises from client-side JavaScript code that processes untrusted data without proper validation or sanitization.
  \paragraph{Vulnerable example (client-side)}
  \begin{figure}[H]
  \begin{lstlisting}[language=HTML]
  <!-- index.html (static) -->
  <div id="msg"></div>
  <script>
    // attacker-controlled: location.hash
    const frag = location.hash.substring(1);
    // UNSAFE: inserts raw HTML from the fragment
    document.getElementById('msg').innerHTML = frag;
  </script>
  \end{lstlisting}
  \end{figure}
\subsection{XSS mitigation}
No single technique can solve XSS, but rather a combination of strategies is required:
\begin{itemize}
    \item Treat all input as untrusted: Any data coming from an external source — including users, third-party services, or even other internal systems — must be treated as untrusted.
    \item Contextual escaping / encoding: Always escape or encode user input according to the context in which it will appear (HTML body, HTML attribute, JavaScript, CSS, URL, etc.). Use the framework’s built-in escaping functions whenever possible.
    \item Sanitize HTML if necessary: If user input needs to include HTML (i.e., formatted comments), use a whitelist-based sanitizer that removes unsafe tags and attributes.
    \item Server-side validation: Validate input for expected format, type, or length. Note that validation alone is insufficient; always combine it with encoding or escaping on output.
\end{itemize}